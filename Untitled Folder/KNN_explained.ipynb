{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K Nearest Neighbors with Python\n",
    "#this is an simple modeling done based on classified data set from a company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dataset : Classified.csv\n",
    "#this data set contains unknown columns in it and the prediction column(target) 0 or 1\n",
    "#We'll try to use KNN to create a model that directly predicts a class for a new data point based off of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lets read the file first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "un = pd.read_csv(\"Classified Data.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
       "1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
       "2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
       "3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
       "4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
       "\n",
       "        PJF       HQE       NXJ  TARGET CLASS  \n",
       "0  0.643798  0.879422  1.231409             1  \n",
       "1  1.013546  0.621552  1.492702             0  \n",
       "2  1.154483  0.957877  1.285597             0  \n",
       "3  1.380003  1.522692  1.153093             1  \n",
       "4  0.646691  1.463812  1.419167             1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 0 to 999\n",
      "Data columns (total 11 columns):\n",
      "WTT             1000 non-null float64\n",
      "PTI             1000 non-null float64\n",
      "EQW             1000 non-null float64\n",
      "SBI             1000 non-null float64\n",
      "LQE             1000 non-null float64\n",
      "QWG             1000 non-null float64\n",
      "FDJ             1000 non-null float64\n",
      "PJF             1000 non-null float64\n",
      "HQE             1000 non-null float64\n",
      "NXJ             1000 non-null float64\n",
      "TARGET CLASS    1000 non-null int64\n",
      "dtypes: float64(10), int64(1)\n",
      "memory usage: 133.8 KB\n"
     ]
    }
   ],
   "source": [
    "un.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WTT             0\n",
       "PTI             0\n",
       "EQW             0\n",
       "SBI             0\n",
       "LQE             0\n",
       "QWG             0\n",
       "FDJ             0\n",
       "PJF             0\n",
       "HQE             0\n",
       "NXJ             0\n",
       "TARGET CLASS    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#so we can see that there are columns that we dont know what they mean as it is classified\n",
    "#hence can't predict which column is important and which is not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this data should be scaled\n",
    "#Because the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, \n",
    "#the scale of the variables matters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#KNN uses the euclidean distant measure which is sensitive to magnitudes so they should be scaled to all faetures equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scale.fit(un.drop('TARGET CLASS',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaled_features = scale.transform(un.drop('TARGET CLASS',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12354188,  0.18590747, -0.91343069, ..., -1.48236813,\n",
       "        -0.9497194 , -0.64331425],\n",
       "       [-1.08483602, -0.43034845, -1.02531333, ..., -0.20224031,\n",
       "        -1.82805088,  0.63675862],\n",
       "       [-0.78870217,  0.33931821,  0.30151137, ...,  0.28570652,\n",
       "        -0.68249379, -0.37784986],\n",
       "       ...,\n",
       "       [ 0.64177714, -0.51308341, -0.17920486, ..., -2.36249443,\n",
       "        -0.81426092,  0.11159651],\n",
       "       [ 0.46707241, -0.98278576, -1.46519359, ..., -0.03677699,\n",
       "         0.40602453, -0.85567   ],\n",
       "       [-0.38765353, -0.59589427, -1.4313981 , ..., -0.56778932,\n",
       "         0.3369971 ,  0.01034996]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this is the scaled features of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame(scaled_features,columns=un.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123542</td>\n",
       "      <td>0.185907</td>\n",
       "      <td>-0.913431</td>\n",
       "      <td>0.319629</td>\n",
       "      <td>-1.033637</td>\n",
       "      <td>-2.308375</td>\n",
       "      <td>-0.798951</td>\n",
       "      <td>-1.482368</td>\n",
       "      <td>-0.949719</td>\n",
       "      <td>-0.643314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.084836</td>\n",
       "      <td>-0.430348</td>\n",
       "      <td>-1.025313</td>\n",
       "      <td>0.625388</td>\n",
       "      <td>-0.444847</td>\n",
       "      <td>-1.152706</td>\n",
       "      <td>-1.129797</td>\n",
       "      <td>-0.202240</td>\n",
       "      <td>-1.828051</td>\n",
       "      <td>0.636759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.788702</td>\n",
       "      <td>0.339318</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.755873</td>\n",
       "      <td>2.031693</td>\n",
       "      <td>-0.870156</td>\n",
       "      <td>2.599818</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>-0.682494</td>\n",
       "      <td>-0.377850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.060193</td>\n",
       "      <td>-0.621399</td>\n",
       "      <td>0.625299</td>\n",
       "      <td>0.452820</td>\n",
       "      <td>-0.267220</td>\n",
       "      <td>1.750208</td>\n",
       "      <td>1.066491</td>\n",
       "      <td>1.241325</td>\n",
       "      <td>-1.026987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.139275</td>\n",
       "      <td>-0.640392</td>\n",
       "      <td>-0.709819</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>0.822886</td>\n",
       "      <td>-0.936773</td>\n",
       "      <td>0.596782</td>\n",
       "      <td>-1.472352</td>\n",
       "      <td>1.040772</td>\n",
       "      <td>0.276510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0 -0.123542  0.185907 -0.913431  0.319629 -1.033637 -2.308375 -0.798951   \n",
       "1 -1.084836 -0.430348 -1.025313  0.625388 -0.444847 -1.152706 -1.129797   \n",
       "2 -0.788702  0.339318  0.301511  0.755873  2.031693 -0.870156  2.599818   \n",
       "3  0.982841  1.060193 -0.621399  0.625299  0.452820 -0.267220  1.750208   \n",
       "4  1.139275 -0.640392 -0.709819 -0.057175  0.822886 -0.936773  0.596782   \n",
       "\n",
       "        PJF       HQE       NXJ  \n",
       "0 -1.482368 -0.949719 -0.643314  \n",
       "1 -0.202240 -1.828051  0.636759  \n",
       "2  0.285707 -0.682494 -0.377850  \n",
       "3  1.066491  1.241325 -1.026987  \n",
       "4 -1.472352  1.040772  0.276510  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#know we have standardize the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we have scaled the features and it is ready to split as train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we can't do EDA on this as we don't know what he features represent, so we just have to model this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,un['TARGET CLASS'],\n",
    "                                                    test_size=0.40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#so now we will select k=1 at first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=1, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so now we will evaluate our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.94      0.93       201\n",
      "          1       0.94      0.91      0.93       199\n",
      "\n",
      "avg / total       0.93      0.93      0.93       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[189  12]\n",
      " [ 17 182]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#acurracy is good for k=1 as -> 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#let us find out what we get of k from other values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate=[]\n",
    "for i in range(1,25):\n",
    "    \n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we have got the error rate fo this model\n",
    "# select the least error rate and lets again predict the result.\n",
    "#lesser the error rate , more the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Error Rate')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,25),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we can clearly see that error rate is decreased at k=12 so we can find the accuracy at that range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITH K=12\n",
      "\n",
      "\n",
      "confusion matrix\n",
      " [[194   7]\n",
      " [  7 192]]\n",
      "\n",
      "\n",
      "classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.97      0.97       201\n",
      "          1       0.96      0.96      0.96       199\n",
      "\n",
      "avg / total       0.96      0.96      0.96       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=12)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "prediction = knn.predict(X_test)\n",
    "\n",
    "print('WITH K=12')\n",
    "print('\\n')\n",
    "print('confusion matrix\\n',confusion_matrix(y_test,prediction))\n",
    "print('\\n')\n",
    "print('classification report\\n',classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#so we have our highist prediction result here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################           Accuracy --->  0.96              ########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we were able to achieve better accuracy by selecting different k values ."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
